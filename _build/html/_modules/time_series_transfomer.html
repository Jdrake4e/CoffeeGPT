<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>time_series_transfomer &#8212; CoffeeGPT 1.5.4 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css?v=0f882399" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <script src="../_static/documentation_options.js?v=1cd648e3"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">CoffeeGPT 1.5.4 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">time_series_transfomer</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for time_series_transfomer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">file_readin_functions</span> <span class="k">as</span> <span class="nn">frf</span>
<span class="kn">import</span> <span class="nn">utility_functions</span> <span class="k">as</span> <span class="nn">uf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># type: ignore</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">ReduceLROnPlateau</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span> <span class="c1"># type: ignore</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># type: ignore</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">heapq</span>
<span class="kn">from</span> <span class="nn">model_analysis_test_set</span> <span class="kn">import</span> <span class="n">plot_training_history</span>

<div class="viewcode-block" id="TimeSeriesDataset">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.TimeSeriesDataset">[docs]</a>
<span class="k">class</span> <span class="nc">TimeSeriesDataset</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for preparing and processing time series data for deep learning models.</span>
<span class="sd">    </span>
<span class="sd">    This class handles data preparation, scaling, and sequence creation for time series </span>
<span class="sd">    forecasting tasks. It creates train, validation, and test splits and returns them </span>
<span class="sd">    as PyTorch DataLoader objects.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sequence_size : int, default=365</span>
<span class="sd">        The length of each input sequence used for prediction.</span>
<span class="sd">    </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    sequence_size : int</span>
<span class="sd">        The length of each input sequence.</span>
<span class="sd">    scaler : sklearn.preprocessing.StandardScaler</span>
<span class="sd">        Scaler used to standardize features.</span>
<span class="sd">    x_test : torch.Tensor or None</span>
<span class="sd">        The test input sequences after processing.</span>
<span class="sd">    test_data : pandas.DataFrame or None</span>
<span class="sd">        The raw test data split.</span>
<span class="sd">    num_features : int or None</span>
<span class="sd">        The number of features in the processed dataset.</span>
<span class="sd">        </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. Data Processing Flow</span>
<span class="sd">    -----------------------</span>
<span class="sd">    1.1. Data Preparation</span>
<span class="sd">        - Handles splitting data into train, validation, and test sets</span>
<span class="sd">        - Performs standardization of all features</span>
<span class="sd">        - Creates sequence batches for time series modeling</span>
<span class="sd">    </span>
<span class="sd">    1.2. Data Validation</span>
<span class="sd">        - Performs checks for empty datasets after splitting</span>
<span class="sd">        - Validates data dimensions throughout the processing pipeline</span>
<span class="sd">    </span>
<span class="sd">    1.3. Sequence Creation</span>
<span class="sd">        - Converts raw data into overlapping sequences of specified length</span>
<span class="sd">        - Each sequence becomes an input sample, with the next value as target</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; # Load time series data</span>
<span class="sd">    &gt;&gt;&gt; data = pd.read_csv(&#39;stock_data.csv&#39;)</span>
<span class="sd">    &gt;&gt;&gt; # Create dataset object with sequence length 30</span>
<span class="sd">    &gt;&gt;&gt; dataset = TimeSeriesDataset(sequence_size=30)</span>
<span class="sd">    &gt;&gt;&gt; # Prepare data with 80% training, 20% validation split</span>
<span class="sd">    &gt;&gt;&gt; dataloaders = dataset.prepare_data(data, train_split=0.8, val_split=0.2)</span>
<span class="sd">    &gt;&gt;&gt; # Access the prepared data loaders</span>
<span class="sd">    &gt;&gt;&gt; train_loader = dataloaders[&#39;train&#39;]</span>
<span class="sd">    &gt;&gt;&gt; val_loader = dataloaders[&#39;val&#39;]</span>
<span class="sd">    &gt;&gt;&gt; test_loader = dataloaders[&#39;test&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_size</span><span class="o">=</span><span class="mi">365</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sequence_size</span> <span class="o">=</span> <span class="n">sequence_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_test</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="kc">None</span>
        
<div class="viewcode-block" id="TimeSeriesDataset.prepare_data">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.TimeSeriesDataset.prepare_data">[docs]</a>
    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">train_split</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">val_split</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare time series data for model training and evaluation.</span>
<span class="sd">        </span>
<span class="sd">        This method handles data splitting, scaling, and sequence creation.</span>
<span class="sd">        It splits the data into train, validation, and test sets, scales the</span>
<span class="sd">        features, and creates overlapping sequences for time series prediction.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : pandas.DataFrame</span>
<span class="sd">            Input time series data with a &#39;Date&#39; column and feature columns.</span>
<span class="sd">        train_split : float, default=0.8</span>
<span class="sd">            Proportion of data to use for training (0.0 to 1.0).</span>
<span class="sd">        val_split : float, default=0.8</span>
<span class="sd">            Proportion of training data to use for validation (0.0 to 1.0).</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing DataLoader objects for &#39;train&#39;, &#39;val&#39;, and &#39;test&#39; sets.</span>
<span class="sd">            </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If any of the resulting datasets are empty after splitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1">#TODO find a nicer solution to this bugfix</span>
        <span class="c1"># DO NOT CHANGE THESE PRINTS FIXS A STUPID BUG WHERE test_data WAS BECOMING EMPTY</span>
        <span class="c1"># Still have no clue why this behavior is occuring</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initial data shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    
        <span class="c1"># Drop missing values and date column</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After dropna shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        
        <span class="c1"># Calculate split indices</span>
        <span class="n">train_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">train_split</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train index:&quot;</span><span class="p">,</span> <span class="n">train_idx</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total data length:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test data shape:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        
        <span class="c1"># First check if data is empty</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input data is empty&quot;</span><span class="p">)</span>
        
        <span class="c1"># Calculate split indices</span>
        <span class="n">train_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">train_split</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">train_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Train split results in empty training set&quot;</span><span class="p">)</span>
        
        <span class="c1"># Drop missing values and date column</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Split data</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">train_idx</span><span class="p">]</span>
        <span class="n">test_data</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">:]</span>
        
        <span class="n">val_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">*</span> <span class="n">val_split</span><span class="p">)</span>
        <span class="n">validation_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_idx</span><span class="p">:]</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">val_idx</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Training data is empty after splitting&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Validation data is empty after splitting&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Test data is empty after splitting&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Store number of features</span>
        
        <span class="c1"># Scale all features including target</span>
        <span class="n">train_scaled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale_data</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
        <span class="n">val_scaled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale_data</span><span class="p">(</span><span class="n">validation_data</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">test_scaled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale_data</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_data_loaders</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">val_scaled</span><span class="p">,</span> <span class="n">test_scaled</span><span class="p">)</span></div>

    
    <span class="k">def</span> <span class="nf">_scale_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Scale data using StandardScaler.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : pandas.DataFrame</span>
<span class="sd">            Data to be scaled.</span>
<span class="sd">        fit : bool, default=True</span>
<span class="sd">            Whether to fit the scaler on this data or use previously fitted parameters.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.ndarray</span>
<span class="sd">            Scaled data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">fit</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_create_sequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create overlapping sequences for time series prediction.</span>
<span class="sd">        </span>
<span class="sd">        Takes input data and creates sequences of length `sequence_size`,</span>
<span class="sd">        with the target being the next value after each sequence.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : numpy.ndarray</span>
<span class="sd">            Scaled input data.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple of torch.Tensor</span>
<span class="sd">            Input sequences and corresponding target values. </span>
<span class="sd">            Index 0 will have the features and index 1 will have the target</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        
        <span class="c1"># Create sequences for each feature</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_size</span><span class="p">):</span>
            <span class="c1"># Extract sequence for all features</span>
            <span class="n">sequence</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_size</span><span class="p">)]</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_size</span><span class="p">,</span> <span class="n">num_features</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Assuming Price is the first column</span>
            
            <span class="c1"># Reshape sequence to have features as the offset</span>
            <span class="c1"># Original shape: (sequence_size, num_features)</span>
            <span class="c1"># New shape: (sequence_size * num_features)</span>
            <span class="n">sequence</span> <span class="o">=</span> <span class="n">sequence</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            
            <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
            <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
        
        <span class="c1"># Reshape x to (num_sequences, sequence_size, num_features)</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_size</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
        <span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x_tensor</span><span class="p">,</span> <span class="n">y_tensor</span>
    
    <span class="k">def</span> <span class="nf">_create_data_loaders</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create PyTorch DataLoader objects from sequence data.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        train_data : numpy.ndarray</span>
<span class="sd">            Scaled training data.</span>
<span class="sd">        val_data : numpy.ndarray</span>
<span class="sd">            Scaled validation data.</span>
<span class="sd">        test_data : numpy.ndarray</span>
<span class="sd">            Scaled test data.</span>
<span class="sd">        batch_size : int, default=32</span>
<span class="sd">            Batch size for the data loaders.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing DataLoader objects for &#39;train&#39;, &#39;val&#39;, and &#39;test&#39; sets.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_sequences</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
        <span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_sequences</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>
        <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_sequences</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span>
        
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
        <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">),</span>
            <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="PositionalEncoding">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.PositionalEncoding">[docs]</a>
<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements positional encoding for Transformer models.</span>
<span class="sd">    </span>
<span class="sd">    This module adds positional information to the input embeddings for sequence models,</span>
<span class="sd">    allowing the model to leverage sequence order information despite the parallelized</span>
<span class="sd">    nature of Transformer architectures.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    d_model : int</span>
<span class="sd">        Dimension of the model&#39;s embeddings.</span>
<span class="sd">    dropout : float, default=0.1</span>
<span class="sd">        Dropout rate to apply after adding positional encodings.</span>
<span class="sd">    max_len : int, default=5000</span>
<span class="sd">        Maximum sequence length the model can handle.</span>
<span class="sd">        </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. Implementation Details</span>
<span class="sd">    -----------------------</span>
<span class="sd">    1.1. Sinusoidal Encoding</span>
<span class="sd">        - Uses sine and cosine functions of different frequencies for position encoding</span>
<span class="sd">        - Position enc(pos, 2i) = sin(pos/10000^(2i/d_model))</span>
<span class="sd">        - Position enc(pos, 2i+1) = cos(pos/10000^(2i/d_model))</span>
<span class="sd">    </span>
<span class="sd">    1.2. Benefits</span>
<span class="sd">        - Allows model to generalize to sequence lengths not seen during training</span>
<span class="sd">        - Provides consistent relative position information</span>
<span class="sd">        - Enables the model to capture sequential patterns and dependencies</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; # Create positional encoding for embedding dimension 512</span>
<span class="sd">    &gt;&gt;&gt; pos_encoder = PositionalEncoding(d_model=512, dropout=0.1, max_len=1000)</span>
<span class="sd">    &gt;&gt;&gt; # Apply to an input tensor of shape [sequence_length, batch_size, embedding_dim]</span>
<span class="sd">    &gt;&gt;&gt; input_tensor = torch.zeros(100, 32, 512)  # [seq_len, batch, d_model]</span>
<span class="sd">    &gt;&gt;&gt; output = pos_encoder(input_tensor)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

        <span class="c1"># Create positional encoding matrix</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        
        <span class="c1"># Add batch dimension and store</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;pe&#39;</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>

<div class="viewcode-block" id="PositionalEncoding.forward">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.PositionalEncoding.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add positional encoding to input tensor.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input tensor of shape [seq_len, batch_size, d_model]</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Tensor with added positional encodings, same shape as input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="ModelTuningLogger">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTuningLogger">[docs]</a>
<span class="k">class</span> <span class="nc">ModelTuningLogger</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logger for tracking model configurations and performance metrics during tuning.</span>
<span class="sd">    </span>
<span class="sd">    This class handles saving and loading experiment results, including model</span>
<span class="sd">    configurations, training history, and validation performance.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    log_dir : str, default=&#39;logs&#39;</span>
<span class="sd">        Directory to save experiment logs.</span>
<span class="sd">    experiment_name : str, optional</span>
<span class="sd">        Name of the experiment. If None, a timestamp will be used.</span>
<span class="sd">        </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    log_dir : Path</span>
<span class="sd">        Path to the log directory.</span>
<span class="sd">    experiment_name : str</span>
<span class="sd">        Name of the current experiment.</span>
<span class="sd">    results : dict</span>
<span class="sd">        Dictionary to store experiment results.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;logs&#39;</span><span class="p">,</span> <span class="n">experiment_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">experiment_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;experiment_</span><span class="si">{</span><span class="n">timestamp</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">experiment_name</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        
<div class="viewcode-block" id="ModelTuningLogger.log_experiment">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTuningLogger.log_experiment">[docs]</a>
    <span class="k">def</span> <span class="nf">log_experiment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">training_history</span><span class="p">,</span> <span class="n">val_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Log experiment details and results.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_config : dict</span>
<span class="sd">            Dictionary containing model configuration parameters.</span>
<span class="sd">        training_history : dict</span>
<span class="sd">            Dictionary containing training history (losses, epochs, etc.).</span>
<span class="sd">        val_metrics : dict, optional</span>
<span class="sd">            Dictionary containing validation metrics.</span>
<span class="sd">        test_metrics : dict, optional</span>
<span class="sd">            Dictionary containing test metrics.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        str</span>
<span class="sd">            Path to the saved JSON file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate a unique ID for this configuration</span>
        <span class="n">config_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;config_</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>
        
        <span class="c1"># Create experiment record</span>
        <span class="n">experiment</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model_config&quot;</span><span class="p">:</span> <span class="n">model_config</span><span class="p">,</span>
            <span class="s2">&quot;training_history&quot;</span><span class="p">:</span> <span class="n">training_history</span><span class="p">,</span>
        <span class="p">}</span>
        
        <span class="k">if</span> <span class="n">val_metrics</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">experiment</span><span class="p">[</span><span class="s2">&quot;validation_metrics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_metrics</span>
            
        <span class="k">if</span> <span class="n">test_metrics</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">experiment</span><span class="p">[</span><span class="s2">&quot;test_metrics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_metrics</span>
        
        <span class="c1"># Add to results dictionary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="n">config_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">experiment</span>
        
        <span class="c1"># Save to file</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_results</span><span class="p">()</span></div>

    
<div class="viewcode-block" id="ModelTuningLogger.save_results">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTuningLogger.save_results">[docs]</a>
    <span class="k">def</span> <span class="nf">save_results</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save all experiment results to a JSON file.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        str</span>
<span class="sd">            Path to the saved JSON file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="si">}</span><span class="s2">.json&quot;</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Convert results to JSON serializable format</span>
            <span class="n">serializable_results</span> <span class="o">=</span> <span class="n">uf</span><span class="o">.</span><span class="n">convert_to_serializable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">)</span>
            
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">serializable_results</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                
        <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Could not serialize results directly: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="ModelTuningLogger.load_results">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTuningLogger.load_results">[docs]</a>
    <span class="k">def</span> <span class="nf">load_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load experiment results from a JSON file.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        file_path : str, optional</span>
<span class="sd">            Path to the JSON file. If None, uses the current experiment name.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing loaded experiment results.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">file_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">file_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="si">}</span><span class="s2">.json&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">file_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
            
        <span class="k">if</span> <span class="n">file_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No results file found at </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">results</span></div>

    
<div class="viewcode-block" id="ModelTuningLogger.get_best_config">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTuningLogger.get_best_config">[docs]</a>
    <span class="k">def</span> <span class="nf">get_best_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the best configuration based on a specific metric.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        metric : str, default=&#39;val_loss&#39;</span>
<span class="sd">            Metric to use for comparison.</span>
<span class="sd">        mode : str, default=&#39;min&#39;</span>
<span class="sd">            &#39;min&#39; for metrics where lower is better (e.g., loss),</span>
<span class="sd">            &#39;max&#39; for metrics where higher is better (e.g., accuracy).</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            (config_id, config_dict) of the best configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No results available&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
            
        <span class="n">best_score</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
        <span class="n">best_config_id</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="k">for</span> <span class="n">config_id</span><span class="p">,</span> <span class="n">experiment</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Check if the metric exists in validation metrics</span>
            <span class="k">if</span> <span class="s1">&#39;validation_metrics&#39;</span> <span class="ow">in</span> <span class="n">experiment</span> <span class="ow">and</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">experiment</span><span class="p">[</span><span class="s1">&#39;validation_metrics&#39;</span><span class="p">]:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">experiment</span><span class="p">[</span><span class="s1">&#39;validation_metrics&#39;</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span>
            <span class="c1"># Or check if it&#39;s in training history</span>
            <span class="k">elif</span> <span class="s1">&#39;training_history&#39;</span> <span class="ow">in</span> <span class="n">experiment</span> <span class="ow">and</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">experiment</span><span class="p">[</span><span class="s1">&#39;training_history&#39;</span><span class="p">]:</span>
                <span class="c1"># If it&#39;s a list, take the best value</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">experiment</span><span class="p">[</span><span class="s1">&#39;training_history&#39;</span><span class="p">][</span><span class="n">metric</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
                        <span class="n">score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">experiment</span><span class="p">[</span><span class="s1">&#39;training_history&#39;</span><span class="p">][</span><span class="n">metric</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">experiment</span><span class="p">[</span><span class="s1">&#39;training_history&#39;</span><span class="p">][</span><span class="n">metric</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">score</span> <span class="o">=</span> <span class="n">experiment</span><span class="p">[</span><span class="s1">&#39;training_history&#39;</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">continue</span>
                
            <span class="k">if</span> <span class="p">(</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span> <span class="ow">and</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="n">best_score</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span> <span class="ow">and</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">):</span>
                <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
                <span class="n">best_config_id</span> <span class="o">=</span> <span class="n">config_id</span>
                
        <span class="k">if</span> <span class="n">best_config_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No configuration found with metric </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
            
        <span class="k">return</span> <span class="n">best_config_id</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="n">best_config_id</span><span class="p">]</span></div>
</div>


<span class="c1">#TODO Verify documentation again for this section</span>
<div class="viewcode-block" id="TransformerModel">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.TransformerModel">[docs]</a>
<span class="k">class</span> <span class="nc">TransformerModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transformer-based model for time series forecasting.</span>
<span class="sd">    </span>
<span class="sd">    This model uses a Transformer encoder architecture to process multivariate</span>
<span class="sd">    time series data and predict future values.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    input_dim : int</span>
<span class="sd">        Number of input features.</span>
<span class="sd">    d_model : int, default=512</span>
<span class="sd">        Dimension of the model embeddings and transformer layers.</span>
<span class="sd">    nhead : int, default=8</span>
<span class="sd">        Number of attention heads in transformer layers.</span>
<span class="sd">    num_layers : int, default=2</span>
<span class="sd">        Number of transformer encoder layers.</span>
<span class="sd">    dropout : float, default=0.1</span>
<span class="sd">        Dropout rate used throughout the model.</span>
<span class="sd">    decoder_config : dict, optional</span>
<span class="sd">        Configuration for the decoder network. If None, a default decoder is used.</span>
<span class="sd">        Expected keys:</span>
<span class="sd">        - hidden_layers: list of tuples (size, activation)</span>
<span class="sd">        - use_batch_norm: bool</span>
<span class="sd">        - dropout: float</span>
<span class="sd">        </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. Architecture Components</span>
<span class="sd">    ------------------------</span>
<span class="sd">    1.1. Input Encoding</span>
<span class="sd">        - Linear projection from input features to model dimension</span>
<span class="sd">        - Positional encoding to preserve sequence order information</span>
<span class="sd">    </span>
<span class="sd">    1.2. Transformer Encoder</span>
<span class="sd">        - Multi-head self-attention mechanism</span>
<span class="sd">        - Feedforward neural networks</span>
<span class="sd">        - Layer normalization and residual connections</span>
<span class="sd">    </span>
<span class="sd">    1.3. Output Decoder</span>
<span class="sd">        - Multi-layer feedforward neural network</span>
<span class="sd">        - Progressively reduces dimensions to final output</span>
<span class="sd">    </span>
<span class="sd">    2. Prediction Process</span>
<span class="sd">    -------------------</span>
<span class="sd">    2.1. Feature Encoding</span>
<span class="sd">        - Each timestep&#39;s features are encoded to the model dimension</span>
<span class="sd">    </span>
<span class="sd">    2.2. Sequence Processing</span>
<span class="sd">        - Transformer layers process the entire sequence in parallel</span>
<span class="sd">        - Self-attention captures dependencies between different timesteps</span>
<span class="sd">    </span>
<span class="sd">    2.3. Prediction Generation</span>
<span class="sd">        - The final timestep representation is used for prediction</span>
<span class="sd">        - Decoder network produces the final output value</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; # Create a transformer model for time series with 5 features</span>
<span class="sd">    &gt;&gt;&gt; model = TransformerModel(input_dim=5, d_model=256, nhead=4, num_layers=2)</span>
<span class="sd">    &gt;&gt;&gt; # Process a batch of 32 sequences, each with 100 timesteps and 5 features</span>
<span class="sd">    &gt;&gt;&gt; batch = torch.randn(32, 100, 5)  # [batch_size, seq_length, features]</span>
<span class="sd">    &gt;&gt;&gt; output = model(batch)  # Shape: [batch_size, 1]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">decoder_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># Modified encoder to handle multivariate input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        
        <span class="n">encoder_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">nhead</span><span class="o">=</span><span class="n">nhead</span><span class="p">,</span>
            <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># Important for handling batch-first input</span>
        <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layers</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
        
        <span class="c1"># Create decoder based on configuration</span>
        <span class="k">if</span> <span class="n">decoder_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Default decoder configuration</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">RReLU</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Fixed dimension calculation</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Custom decoder based on provided configuration</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">input_size</span> <span class="o">=</span> <span class="n">d_model</span>
            
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">decoder_config</span><span class="p">[</span><span class="s2">&quot;hidden_layers&quot;</span><span class="p">]):</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                
                <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Only add activation if specified</span>
                    <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;relu&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;gelu&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;tanh&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;silu&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;elu&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;prelu&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
                        <span class="c1"># Use Identity for linear activation to make it explicit</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;rrelu&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">RReLU</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;celu&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>
                    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;softplus&quot;</span><span class="p">:</span>
                        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">())</span>
                
                <span class="k">if</span> <span class="n">decoder_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_batch_norm&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">decoder_config</span><span class="p">[</span><span class="s2">&quot;hidden_layers&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>
                
                <span class="k">if</span> <span class="n">decoder_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">decoder_config</span><span class="p">[</span><span class="s2">&quot;hidden_layers&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">decoder_config</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]))</span>
                
                <span class="n">input_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
            
            <span class="c1"># No need for output layer since it&#39;s included in hidden_layers</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
<div class="viewcode-block" id="TransformerModel.forward">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.TransformerModel.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the transformer model.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input tensor of shape [batch_size, seq_length, num_features]</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Output tensor of shape [batch_size, 1] containing predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Store the input sequence for use in loss calculation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_input_sequence</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        
        <span class="c1"># Linear encoding of each timestep&#39;s features</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [batch_size, seq_length, d_model]</span>
        
        <span class="c1"># Apply positional encoding</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># [seq_length, batch_size, d_model]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, seq_length, d_model]</span>
        
        <span class="c1"># Pass through transformer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [batch_size, seq_length, d_model]</span>
        
        <span class="c1"># Take the last sequence element and decode</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># [batch_size, d_model]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        
        <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="TransformerModel.generate_forecast">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.TransformerModel.generate_forecast">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_forecast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_sequence</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate multi-step forecasts with uncertainty quantification.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initial_sequence : torch.Tensor</span>
<span class="sd">            Initial sequence of shape [1, sequence_length, num_features]</span>
<span class="sd">        num_steps : int</span>
<span class="sd">            Number of steps to forecast into the future</span>
<span class="sd">        temperature : float, default=0.1</span>
<span class="sd">            Base temperature for uncertainty. Higher values = more uncertainty</span>
<span class="sd">        num_samples : int, default=100</span>
<span class="sd">            Number of Monte Carlo samples to generate</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing:</span>
<span class="sd">            - &#39;mean&#39;: Mean predictions for each future step</span>
<span class="sd">            - &#39;std&#39;: Standard deviation of predictions</span>
<span class="sd">            - &#39;samples&#39;: All Monte Carlo samples if num_samples &gt; 1</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set to evaluation mode</span>
        <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        
        <span class="c1"># Ensure initial sequence is on correct device</span>
        <span class="n">initial_sequence</span> <span class="o">=</span> <span class="n">initial_sequence</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Initialize storage for all samples</span>
        <span class="n">all_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
                <span class="n">current_sequence</span> <span class="o">=</span> <span class="n">initial_sequence</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                
                <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
                    <span class="c1"># Generate base prediction</span>
                    <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">current_sequence</span><span class="p">)</span>
                    
                    <span class="c1"># Add noise scaled by step number (increasing uncertainty)</span>
                    <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Only add noise if we&#39;re doing Monte Carlo</span>
                        <span class="n">step_temp</span> <span class="o">=</span> <span class="n">temperature</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">step</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># Increase temperature with horizon</span>
                        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">step_temp</span><span class="p">))</span>
                        <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">+</span> <span class="n">noise</span>
                    
                    <span class="c1"># Store prediction</span>
                    <span class="n">all_samples</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                    
                    <span class="c1"># Update sequence for next prediction</span>
                    <span class="c1"># Remove oldest timestep and add our prediction</span>
                    <span class="n">current_sequence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
                        <span class="n">current_sequence</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:],</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
                            <span class="n">current_sequence</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># Keep other features unchanged</span>
                            <span class="n">prediction</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Add our new prediction</span>
                        <span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                    <span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Calculate statistics</span>
        <span class="n">mean_predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">std_predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">all_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="n">mean_predictions</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="s1">&#39;std&#39;</span><span class="p">:</span> <span class="n">std_predictions</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="s1">&#39;samples&#39;</span><span class="p">:</span> <span class="n">all_samples</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">}</span></div>
</div>


<span class="c1">#TODO Save json of all configurations and performance</span>
<span class="c1">#TODO Bring over other tuning grid from depricated version</span>
<div class="viewcode-block" id="create_decoder_grid">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.create_decoder_grid">[docs]</a>
<span class="k">def</span> <span class="nf">create_decoder_grid</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a grid of decoder configurations for hyperparameter tuning.</span>

<span class="sd">    This function generates a comprehensive set of decoder architectures by varying</span>
<span class="sd">    layer widths, activation functions, batch normalization, and dropout rates.</span>
<span class="sd">    The configurations are designed specifically for time series forecasting.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    d_model : int, default=512</span>
<span class="sd">        Dimension of the transformer model&#39;s embeddings. This value is used to scale </span>
<span class="sd">        the decoder layer widths proportionally.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list of dict</span>
<span class="sd">        List of decoder configurations. Each dictionary contains:</span>
<span class="sd">        </span>
<span class="sd">        - hidden_layers : list of tuples (size, activation)</span>
<span class="sd">            Layer architecture with sizes and activation types</span>
<span class="sd">        - use_batch_norm : bool</span>
<span class="sd">            Whether to use batch normalization between layers</span>
<span class="sd">        - dropout : float</span>
<span class="sd">            Dropout rate to apply between hidden layers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Define the search space</span>
    <span class="n">hidden_layer_widths</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[</span><span class="n">d_model</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">//</span> <span class="mi">4</span><span class="p">],</span>  <span class="c1"># Default progressive reduction</span>
        <span class="p">[</span><span class="n">d_model</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">//</span> <span class="mi">8</span><span class="p">],</span>  <span class="c1"># Deeper reduction</span>
        <span class="c1">#[d_model // 2],  # Single hidden layer</span>
        <span class="c1">#[d_model // 3, d_model // 9],  # Steeper reduction</span>
        <span class="c1">#[d_model // 2, d_model // 2, d_model // 4],  # Wide middle layer</span>
        <span class="c1">#[d_model // 2, d_model // 8, d_model // 4],  # Bottleneck architecture</span>
        <span class="c1">#[d_model, d_model // 2, d_model // 4],  # Wide initial layer</span>
    <span class="p">]</span>
    
    <span class="c1"># Optimized activation functions for time series</span>
    <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1">#&quot;gelu&quot;,      # Smooth gradient, works well with transformers</span>
        <span class="c1">#&quot;elu&quot;,       # Good for time series, handles negative values well</span>
        <span class="c1">#&quot;prelu&quot;,     # Learnable negative slope</span>
        <span class="c1">#&quot;silu&quot;,      # Smooth, non-monotonic</span>
        <span class="c1">#&quot;leaky_relu&quot;, # Simple but effective negative slope</span>
        <span class="c1">#&quot;linear&quot;,    # Linear activation, good baseline for time series</span>
        <span class="s2">&quot;rrelu&quot;</span><span class="c1">#,     # Randomized ReLU, good for noisy data</span>
        <span class="c1">#&quot;celu&quot;,      # Continuously differentiable ELU</span>
        <span class="c1">#&quot;softplus&quot;   # Smooth approximation of ReLU</span>
    <span class="p">]</span>
    
    <span class="n">use_batch_norm</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="c1"># [False, True] </span>
    <span class="n">dropout_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">]</span>
    
    <span class="c1"># Generate all possible decoder configurations</span>
    <span class="n">decoder_configs</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">width_config</span> <span class="ow">in</span> <span class="n">hidden_layer_widths</span><span class="p">:</span>
        <span class="c1"># Try all combinations of the same activation through the network</span>
        <span class="k">for</span> <span class="n">act</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">batch_norm</span> <span class="ow">in</span> <span class="n">use_batch_norm</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">dropout</span> <span class="ow">in</span> <span class="n">dropout_rates</span><span class="p">:</span>
                    <span class="c1"># Add hidden layers with activation</span>
                    <span class="n">hidden_layers</span> <span class="o">=</span> <span class="p">[(</span><span class="n">size</span><span class="p">,</span> <span class="n">act</span><span class="p">)</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">width_config</span><span class="p">]</span>
                    <span class="c1"># Add final output layer with no activation</span>
                    <span class="n">hidden_layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                    
                    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s2">&quot;hidden_layers&quot;</span><span class="p">:</span> <span class="n">hidden_layers</span><span class="p">,</span>
                        <span class="s2">&quot;use_batch_norm&quot;</span><span class="p">:</span> <span class="n">batch_norm</span><span class="p">,</span>
                        <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout</span>
                    <span class="p">}</span>
                    
                    <span class="n">decoder_configs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        
        <span class="c1">#TODO Try all mixed activation functions, for now only first two architectures</span>
        <span class="k">if</span> <span class="n">width_config</span> <span class="ow">in</span> <span class="p">[</span><span class="n">hidden_layer_widths</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden_layer_widths</span><span class="p">[</span><span class="mi">1</span><span class="p">]]:</span>
            <span class="n">act_combinations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">(</span><span class="n">activations</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">width_config</span><span class="p">)))</span>
            
            <span class="k">for</span> <span class="n">acts</span> <span class="ow">in</span> <span class="n">act_combinations</span><span class="p">:</span>
                <span class="c1"># Add hidden layers with mixed activations</span>
                <span class="n">hidden_layers</span> <span class="o">=</span> <span class="p">[(</span><span class="n">width_config</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">act</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">act</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">acts</span><span class="p">)]</span>
                <span class="c1"># Add final output layer with no activation</span>
                <span class="n">hidden_layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                
                <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;hidden_layers&quot;</span><span class="p">:</span> <span class="n">hidden_layers</span><span class="p">,</span>
                    <span class="s2">&quot;use_batch_norm&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># Fixed for mixed activations</span>
                    <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="mf">0.2</span>  <span class="c1"># Fixed middle dropout for mixed activations</span>
                <span class="p">}</span>
                
                <span class="n">decoder_configs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">decoder_configs</span></div>


<span class="c1">#TODO Update Documentation</span>
<div class="viewcode-block" id="ModelTrainer">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTrainer">[docs]</a>
<span class="k">class</span> <span class="nc">ModelTrainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A comprehensive trainer class for time series forecasting models with PyTorch.</span>
<span class="sd">    </span>
<span class="sd">    This class manages the complete training lifecycle of deep learning models, including:</span>
<span class="sd">    - Model training with customizable loss functions</span>
<span class="sd">    - Validation and early stopping</span>
<span class="sd">    - Learning rate scheduling</span>
<span class="sd">    - Model evaluation</span>
<span class="sd">    - Forecasting with uncertainty quantification</span>
<span class="sd">    - Experiment logging and model checkpointing</span>
<span class="sd">    </span>
<span class="sd">    The trainer supports various loss functions optimized for time series forecasting:</span>
<span class="sd">    - MSE (default)</span>
<span class="sd">    - Custom weighted loss</span>
<span class="sd">    - Asymptote prevention loss</span>
<span class="sd">    - Adaptive forecast loss</span>
<span class="sd">    </span>
<span class="sd">    Features:</span>
<span class="sd">    - Automatic early stopping based on validation loss</span>
<span class="sd">    - Learning rate scheduling with ReduceLROnPlateau</span>
<span class="sd">    - Monte Carlo sampling for uncertainty quantification in forecasts</span>
<span class="sd">    - Experiment tracking and logging</span>
<span class="sd">    - Model checkpointing and best model saving</span>
<span class="sd">    - Comprehensive training history tracking</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        The PyTorch model to train (typically a TransformerModel instance).</span>
<span class="sd">    device : torch.device</span>
<span class="sd">        The device to use for training (CPU or CUDA).</span>
<span class="sd">    learning_rate : float, default=1e-4</span>
<span class="sd">        Initial learning rate for the AdamW optimizer.</span>
<span class="sd">    model_config : dict, optional</span>
<span class="sd">        Configuration dictionary for model architecture and parameters.</span>
<span class="sd">        Used for experiment logging and reproducibility.</span>
<span class="sd">    logger : ModelTuningLogger, optional</span>
<span class="sd">        Logger instance for tracking experiments and saving results.</span>
<span class="sd">        If provided, will log training metrics, validation results,</span>
<span class="sd">        and model configurations.</span>
<span class="sd">    loss_config : dict, optional</span>
<span class="sd">        Configuration for the loss function. Should contain:</span>
<span class="sd">        - &#39;type&#39;: str, one of [&#39;mse&#39;, &#39;custom&#39;, &#39;asymptote_prevention&#39;, &#39;adaptive_forecast&#39;]</span>
<span class="sd">        - Additional parameters specific to each loss type:</span>
<span class="sd">            - custom: {&#39;alpha&#39;, &#39;beta&#39;, &#39;gamma&#39;}</span>
<span class="sd">            - asymptote_prevention: {&#39;historical_range&#39;, &#39;max_daily_change&#39;}</span>
<span class="sd">            - adaptive_forecast: {&#39;historical_range&#39;, &#39;forecast_steps&#39;, &#39;init_max_change&#39;,</span>
<span class="sd">                                &#39;init_range_weight&#39;, &#39;init_change_weight&#39;}</span>
<span class="sd">    </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    validation_loss_history : list</span>
<span class="sd">        History of validation losses during training.</span>
<span class="sd">    training_loss_history : list</span>
<span class="sd">        History of training losses during training.</span>
<span class="sd">    epoch_history : list</span>
<span class="sd">        List of completed epochs.</span>
<span class="sd">    lr_history : list</span>
<span class="sd">        History of learning rates during training.</span>
<span class="sd">    optimizer : torch.optim.AdamW</span>
<span class="sd">        The optimizer instance with weight decay.</span>
<span class="sd">    scheduler : torch.optim.lr_scheduler.ReduceLROnPlateau</span>
<span class="sd">        Learning rate scheduler that reduces LR on plateau.</span>
<span class="sd">    criterion : torch.nn.Module</span>
<span class="sd">        The loss function based on loss_config.</span>
<span class="sd">    </span>
<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    train(data_loaders, epochs=1000, patience=10, model_dir=&#39;models&#39;, experiment_name=None)</span>
<span class="sd">        Main training loop with early stopping and checkpointing.</span>
<span class="sd">    train_epoch(train_loader)</span>
<span class="sd">        Trains the model for one epoch.</span>
<span class="sd">    validate(val_loader)</span>
<span class="sd">        Validates the model on validation data.</span>
<span class="sd">    evaluate(test_loader)</span>
<span class="sd">        Evaluates the model on test data.</span>
<span class="sd">    forecast(initial_sequence, num_steps, temperature=0.1, num_samples=100)</span>
<span class="sd">        Generates probabilistic forecasts with uncertainty quantification.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">model_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="c1"># Store model configuration, empty dict if no model_config provided</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">model_config</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="c1"># Initialize logger if provided</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logger</span>
        
        <span class="c1"># Default loss configuration</span>
        <span class="n">default_loss_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;mse&#39;</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span> <span class="o">=</span> <span class="n">loss_config</span> <span class="ow">or</span> <span class="n">default_loss_config</span>
        
        <span class="c1"># Initialize loss function and move to correct device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_loss_function</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Initialize optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
            <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span>
        <span class="p">)</span>
        
        <span class="c1"># Initialize scheduler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span>
            <span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        
        <span class="c1"># Initialize history trackers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_history</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">def</span> <span class="nf">_initialize_loss_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the loss function based on configuration.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.nn.Module</span>
<span class="sd">            Initialized loss function.</span>
<span class="sd">        </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If loss type is not recognized or required parameters are missing.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loss_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;mse&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;mse&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        
        <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;directional&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">DirectionalLoss</span><span class="p">(</span>
                <span class="n">direction_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;direction_weight&#39;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>
                <span class="n">mse_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;mse_scale&#39;</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
            <span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">CustomLoss</span><span class="p">(</span>
                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>
                <span class="n">beta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>
                <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
            <span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;asymptote_prevention&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;historical_range&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;historical_range required for asymptote_prevention loss&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">AsymptotePreventionLoss</span><span class="p">(</span>
                <span class="n">historical_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="p">[</span><span class="s1">&#39;historical_range&#39;</span><span class="p">],</span>
                <span class="n">max_daily_change</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_daily_change&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
            <span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;forecast_based&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ForecastBasedLoss</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">forecast_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;forecast_steps&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                <span class="n">forecast_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;forecast_weight&#39;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>
                <span class="n">temperature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_samples&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
            <span class="p">)</span>
        
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported loss type: </span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
<div class="viewcode-block" id="ModelTrainer.get_available_loss_functions">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTrainer.get_available_loss_functions">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_available_loss_functions</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get information about available loss functions and their parameters.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing loss function descriptions and required parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;mse&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Standard Mean Squared Error loss&#39;</span><span class="p">,</span>
                <span class="s1">&#39;required_params&#39;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="s1">&#39;optional_params&#39;</span><span class="p">:</span> <span class="p">[]</span>
            <span class="p">},</span>
            <span class="s1">&#39;directional&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Combined MSE and cosine similarity loss for directional accuracy&#39;</span><span class="p">,</span>
                <span class="s1">&#39;required_params&#39;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="s1">&#39;optional_params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;direction_weight&#39;</span><span class="p">,</span> <span class="s1">&#39;mse_scale&#39;</span><span class="p">]</span>
            <span class="p">},</span>
            <span class="s1">&#39;custom&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Custom loss combining trend, volatility, and momentum&#39;</span><span class="p">,</span>
                <span class="s1">&#39;required_params&#39;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="s1">&#39;optional_params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">]</span>
            <span class="p">},</span>
            <span class="s1">&#39;asymptote_prevention&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Loss function preventing convergence to asymptotes&#39;</span><span class="p">,</span>
                <span class="s1">&#39;required_params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;historical_range&#39;</span><span class="p">],</span>
                <span class="s1">&#39;optional_params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;max_daily_change&#39;</span><span class="p">]</span>
            <span class="p">},</span>
            <span class="s1">&#39;forecast_based&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Loss function that uses model-generated forecasts to evaluate prediction quality&#39;</span><span class="p">,</span>
                <span class="s1">&#39;required_params&#39;</span><span class="p">:</span> <span class="p">[],</span>
                <span class="s1">&#39;optional_params&#39;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="s1">&#39;forecast_steps&#39;</span><span class="p">,</span>     <span class="c1"># Number of steps to forecast</span>
                    <span class="s1">&#39;forecast_weight&#39;</span><span class="p">,</span>    <span class="c1"># Weight of forecast loss vs immediate loss</span>
                    <span class="s1">&#39;temperature&#39;</span><span class="p">,</span>        <span class="c1"># Temperature for uncertainty</span>
                    <span class="s1">&#39;num_samples&#39;</span>         <span class="c1"># Number of Monte Carlo samples</span>
                <span class="p">]</span>
            <span class="p">}</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="ModelTrainer.train_epoch">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTrainer.train_epoch">[docs]</a>
    <span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the model for one epoch.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        train_loader : torch.utils.data.DataLoader</span>
<span class="sd">            DataLoader containing training data.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Average training loss for the epoch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="ModelTrainer.validate">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTrainer.validate">[docs]</a>
    <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the model on validation data.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        val_loader : torch.utils.data.DataLoader</span>
<span class="sd">            DataLoader containing validation data.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Average validation loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="ModelTrainer.evaluate">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTrainer.evaluate">[docs]</a>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the model on test data.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        test_loader : torch.utils.data.DataLoader</span>
<span class="sd">            DataLoader containing test data.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing test metrics.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ground_truth</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                
                <span class="c1"># Store predictions and ground truth</span>
                <span class="n">predictions</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="n">ground_truth</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">y_batch</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        
        <span class="c1"># Calculate metrics</span>
        <span class="n">mse</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
        <span class="n">mae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)))</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;test_mse&quot;</span><span class="p">:</span> <span class="n">mse</span><span class="p">,</span>
            <span class="s2">&quot;test_mae&quot;</span><span class="p">:</span> <span class="n">mae</span><span class="p">,</span>
            <span class="s2">&quot;test_rmse&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
        <span class="p">}</span></div>

    
<div class="viewcode-block" id="ModelTrainer.train">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTrainer.train">[docs]</a>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loaders</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">model_dir</span><span class="o">=</span><span class="s1">&#39;models&#39;</span><span class="p">,</span> <span class="n">experiment_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the model with early stopping and learning rate scheduling.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data_loaders : dict</span>
<span class="sd">            Dictionary containing DataLoader objects for &#39;train&#39; and &#39;val&#39;.</span>
<span class="sd">        epochs : int, default=1000</span>
<span class="sd">            Maximum number of epochs to train.</span>
<span class="sd">        patience : int, default=10</span>
<span class="sd">            Number of epochs with no improvement after which training will be stopped.</span>
<span class="sd">        model_dir : str, default=&#39;models&#39;</span>
<span class="sd">            Directory to save trained models.</span>
<span class="sd">        experiment_name : str, optional</span>
<span class="sd">            Name for the experiment. Used in the saved model filename.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing training history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create model directory if it doesn&#39;t exist</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># Generate model filename</span>
        <span class="k">if</span> <span class="n">experiment_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">experiment_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;model_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">_%H%M%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        
        <span class="n">model_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">experiment_name</span><span class="si">}</span><span class="s2">_best.pth&quot;</span><span class="p">)</span>
        
        <span class="n">best_val_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
        <span class="n">early_stop_count</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">data_loaders</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span>
            <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">data_loaders</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
            
            <span class="c1"># Get current learning rate</span>
            <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, LR: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">validation_loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epoch_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lr_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
                <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
                <span class="n">early_stop_count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">early_stop_count</span> <span class="o">+=</span> <span class="mi">1</span>
                
            <span class="k">if</span> <span class="n">early_stop_count</span> <span class="o">&gt;=</span> <span class="n">patience</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Early stopping triggered!&quot;</span><span class="p">)</span>
                <span class="k">break</span>
        
        <span class="c1"># Evaluate on test data if available</span>
        <span class="n">test_metrics</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="s1">&#39;test&#39;</span> <span class="ow">in</span> <span class="n">data_loaders</span><span class="p">:</span>
            <span class="n">test_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data_loaders</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test metrics: </span><span class="si">{</span><span class="n">test_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Create training history compatible with json package</span>
        <span class="n">training_history</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_history</span><span class="p">,</span>
            <span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_loss_history</span><span class="p">],</span>  <span class="c1"># Convert all to float</span>
            <span class="s2">&quot;val_loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_loss_history</span><span class="p">],</span>  <span class="c1"># Convert all to float</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span> <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_history</span><span class="p">],</span>  <span class="c1"># Convert all to float</span>
            <span class="s2">&quot;best_val_loss&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">best_val_loss</span><span class="p">),</span>  <span class="c1"># Convert to float</span>
            <span class="s2">&quot;stopped_epoch&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Ensure integer type</span>
        <span class="p">}</span>

        <span class="c1"># Log experiment if logger is available</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">val_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;val_loss&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">best_val_loss</span><span class="p">)}</span>  <span class="c1"># Convert to Python float</span>
            <span class="n">test_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">test_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">if</span> <span class="n">test_metrics</span> <span class="k">else</span> <span class="kc">None</span>  <span class="c1"># Convert test metrics</span>

            <span class="n">log_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_experiment</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">,</span>
                <span class="n">training_history</span><span class="p">,</span>
                <span class="n">val_metrics</span><span class="o">=</span><span class="n">val_metrics</span><span class="p">,</span>
                <span class="n">test_metrics</span><span class="o">=</span><span class="n">test_metrics</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment logged to </span><span class="si">{</span><span class="n">log_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        
        <span class="k">return</span> <span class="n">training_history</span></div>

    
    <span class="c1">#TODO test this out and see if its faster than the current method in monte_carlo_sim.py</span>
<div class="viewcode-block" id="ModelTrainer.forecast">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ModelTrainer.forecast">[docs]</a>
    <span class="k">def</span> <span class="nf">forecast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_sequence</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate forecasts using the trained model.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initial_sequence : torch.Tensor or numpy.ndarray</span>
<span class="sd">            Initial sequence to start forecasting from</span>
<span class="sd">        num_steps : int</span>
<span class="sd">            Number of steps to forecast into the future</span>
<span class="sd">        temperature : float, default=0.1</span>
<span class="sd">            Base temperature for uncertainty in predictions</span>
<span class="sd">        num_samples : int, default=100</span>
<span class="sd">            Number of Monte Carlo samples to generate</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Dictionary containing forecast results:</span>
<span class="sd">            - &#39;mean&#39;: Mean predictions</span>
<span class="sd">            - &#39;std&#39;: Standard deviation of predictions</span>
<span class="sd">            - &#39;samples&#39;: All Monte Carlo samples if num_samples &gt; 1</span>
<span class="sd">            </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This method handles converting the initial sequence to the correct format</span>
<span class="sd">        and device, then uses the model&#39;s generate_forecast method to produce</span>
<span class="sd">        predictions with uncertainty quantification.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># Convert initial sequence to tensor if needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">initial_sequence</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">initial_sequence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">initial_sequence</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="c1"># Add batch dimension if needed</span>
        <span class="k">if</span> <span class="n">initial_sequence</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">initial_sequence</span> <span class="o">=</span> <span class="n">initial_sequence</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Move to correct device</span>
        <span class="n">initial_sequence</span> <span class="o">=</span> <span class="n">initial_sequence</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Generate forecast</span>
        <span class="n">forecast_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate_forecast</span><span class="p">(</span>
            <span class="n">initial_sequence</span><span class="o">=</span><span class="n">initial_sequence</span><span class="p">,</span>
            <span class="n">num_steps</span><span class="o">=</span><span class="n">num_steps</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
            <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">forecast_results</span></div>
</div>


<span class="c1">#TODO Have a json of configs to reload to if an interuption occurs</span>
<span class="c1"># This json will have a list of all remaining parameters to run in and only clear </span>
<div class="viewcode-block" id="run_decoder_tuning">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.run_decoder_tuning">[docs]</a>
<span class="k">def</span> <span class="nf">run_decoder_tuning</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sequence_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> 
                      <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                      <span class="n">plot_training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loss_type</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run comprehensive hyperparameter tuning for decoder architectures.</span>

<span class="sd">    This function performs systematic evaluation of different decoder configurations</span>
<span class="sd">    for transformer models. It handles the complete tuning process including</span>
<span class="sd">    data preparation, model creation, training, evaluation, and result logging.</span>
<span class="sd">    It implements checkpointing to handle interruptions gracefully.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        Input time series data with features and a &#39;Date&#39; column.</span>
<span class="sd">    sequence_size : int, default=30</span>
<span class="sd">        Length of input sequences for the model.</span>
<span class="sd">    d_model : int, default=512</span>
<span class="sd">        Dimension of the transformer model&#39;s embeddings.</span>
<span class="sd">    nhead : int, default=8</span>
<span class="sd">        Number of attention heads in transformer layers.</span>
<span class="sd">    num_layers : int, default=7</span>
<span class="sd">        Number of transformer encoder layers.</span>
<span class="sd">    dropout : float, default=0.2</span>
<span class="sd">        Dropout rate for transformer layers.</span>
<span class="sd">    learning_rate : float, default=1e-4</span>
<span class="sd">        Initial learning rate for optimization.</span>
<span class="sd">    epochs : int, default=50</span>
<span class="sd">        Maximum number of training epochs per configuration.</span>
<span class="sd">    patience : int, default=10</span>
<span class="sd">        Number of epochs without improvement before early stopping.</span>
<span class="sd">    plot_training : bool, default=False</span>
<span class="sd">        Whether to plot training history after each configuration trains.</span>
<span class="sd">    loss_type : str, default=&#39;custom&#39;</span>
<span class="sd">        Type of loss function to use:</span>
<span class="sd">        - &#39;custom&#39;: Uses CustomLoss with trend, volatility, and momentum preservation</span>
<span class="sd">        - &#39;asymptote_prevention&#39;: Uses AsymptotePreventionLoss to prevent convergence</span>
<span class="sd">        - &#39;forecast_based&#39;: Uses ForecastBasedLoss to evaluate prediction quality using forecasts</span>
<span class="sd">        - &#39;mse&#39;: Uses standard MSE loss</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Dictionary containing:</span>
<span class="sd">        </span>
<span class="sd">        - experiment_path : str</span>
<span class="sd">            Path to the experiment directory</span>
<span class="sd">        - top_models : list</span>
<span class="sd">            List of the 5 best performing model configurations and their metrics</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Experimental Design:</span>
<span class="sd">        </span>
<span class="sd">    1. Directory Structure</span>
<span class="sd">        - Creates timestamped experiment directories</span>
<span class="sd">        - Maintains separate directories for models and logs</span>
<span class="sd">        - Saves checkpoints for interruption recovery</span>
<span class="sd">    </span>
<span class="sd">    2. Model Selection</span>
<span class="sd">        - Uses min-heap to track top 5 performing models based on training loss</span>
<span class="sd">        - Saves both model states and configurations for later use</span>
<span class="sd">        - All floating-point values are rounded to 4 decimal places</span>
<span class="sd">    </span>
<span class="sd">    3. Performance Optimization</span>
<span class="sd">        - Implements early stopping for efficient training</span>
<span class="sd">        - Uses GPU acceleration when available</span>
<span class="sd">        - Manages memory through periodic cleanup</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">TimeSeriesDataset</span><span class="p">(</span><span class="n">sequence_size</span><span class="o">=</span><span class="n">sequence_size</span><span class="p">)</span>
    <span class="n">data_loaders</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="c1"># Calculate historical range for loss functions that need it</span>
    <span class="n">price_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">historical_range</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">price_data</span><span class="p">)),</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">price_data</span><span class="p">)))</span>
    
    <span class="c1"># Configure loss function based on type</span>
    <span class="n">loss_config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">loss_type</span>
    <span class="p">}</span>
    
    <span class="c1"># Add parameters based on loss type</span>
    <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;asymptote_prevention&#39;</span><span class="p">:</span>
        <span class="n">loss_config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
            <span class="s1">&#39;historical_range&#39;</span><span class="p">:</span> <span class="n">historical_range</span><span class="p">,</span>
            <span class="s1">&#39;max_daily_change&#39;</span><span class="p">:</span> <span class="mf">0.1</span>
        <span class="p">})</span>
    <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span><span class="p">:</span>
        <span class="n">loss_config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
            <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
            <span class="s1">&#39;beta&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
            <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">0.3</span>
        <span class="p">})</span>
    <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;forecast_based&#39;</span><span class="p">:</span>
        <span class="n">loss_config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
            <span class="s1">&#39;forecast_steps&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s1">&#39;forecast_weight&#39;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
            <span class="s1">&#39;temperature&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="s1">&#39;num_samples&#39;</span><span class="p">:</span> <span class="mi">10</span>
        <span class="p">})</span>
    
    <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S&quot;</span><span class="p">)</span>
    <span class="n">experiment_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;experiments&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;experiment_</span><span class="si">{</span><span class="n">timestamp</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">model_best_path</span> <span class="o">=</span> <span class="n">experiment_path</span> <span class="o">/</span> <span class="s2">&quot;best_models&quot;</span>
    <span class="n">experiment_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">model_best_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">logger</span> <span class="o">=</span> <span class="n">ModelTuningLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">experiment_path</span><span class="p">)</span>
    <span class="n">decoder_configs</span> <span class="o">=</span> <span class="n">create_decoder_grid</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
    
    <span class="n">top_models</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">training_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">checkpoint_file</span> <span class="o">=</span> <span class="n">experiment_path</span> <span class="o">/</span> <span class="s2">&quot;checkpoint.json&quot;</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Initializing training with loss configuration:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">80</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss type: </span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s1">&#39;asymptote_prevention&#39;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Historical range: [</span><span class="si">{</span><span class="n">historical_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">historical_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">loss_config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;historical_range&#39;</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">80</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">config</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">decoder_configs</span><span class="p">)),</span> <span class="n">decoder_configs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Model </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">decoder_configs</span><span class="p">)</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">decoder_configs</span><span class="p">)</span><span class="si">:</span><span class="s1">.2%</span><span class="si">}</span><span class="s1"> done&#39;</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">TransformerModel</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">nhead</span><span class="o">=</span><span class="n">nhead</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">decoder_config</span><span class="o">=</span><span class="n">config</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Print detailed model configuration</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">80</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRAINING MODEL WITH CONFIGURATION:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">80</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Base parameters:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Input dimensions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Embedding dimension (d_model): </span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Attention heads (nhead): </span><span class="si">{</span><span class="n">nhead</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Transformer layers: </span><span class="si">{</span><span class="n">num_layers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Dropout rate: </span><span class="si">{</span><span class="n">dropout</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Learning rate: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Decoder configuration:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Layer architecture: </span><span class="si">{</span><span class="p">[(</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">act</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">act</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;hidden_layers&#39;</span><span class="p">]]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Batch normalization: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;use_batch_norm&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Decoder dropout: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;dropout&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">80</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">ModelTrainer</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> 
            <span class="n">device</span><span class="p">,</span> 
            <span class="n">learning_rate</span><span class="p">,</span> 
            <span class="n">model_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> 
            <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="n">loss_config</span><span class="o">=</span><span class="n">loss_config</span>
        <span class="p">)</span>
        
        <span class="n">training_history</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data_loaders</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span> <span class="n">model_dir</span><span class="o">=</span><span class="n">model_best_path</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">plot_training</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training History Plot:&quot;</span><span class="p">)</span>
            <span class="n">plot_training_history</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
        
        <span class="c1"># Get minimum training loss from history and round to 4 decimal places</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">training_history</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">]),</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">training_history</span><span class="p">[</span><span class="s2">&quot;best_val_loss&quot;</span><span class="p">],</span> <span class="mi">4</span><span class="p">)</span>
        
        <span class="n">model_info</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
            <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span>
            <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span>
            <span class="s1">&#39;loss_config&#39;</span><span class="p">:</span> <span class="n">loss_config</span>  <span class="c1"># Store the complete loss configuration</span>
        <span class="p">}</span>
        
        <span class="c1"># Push to heap based on training loss</span>
        <span class="n">heapq</span><span class="o">.</span><span class="n">heappush</span><span class="p">(</span><span class="n">top_models</span><span class="p">,</span> <span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">model_info</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">top_models</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">5</span><span class="p">:</span>
            <span class="n">heapq</span><span class="o">.</span><span class="n">heappop</span><span class="p">(</span><span class="n">top_models</span><span class="p">)</span>
        
        <span class="n">training_losses</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
            <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span>
            <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span>
            <span class="s1">&#39;loss_config&#39;</span><span class="p">:</span> <span class="n">loss_config</span>
        <span class="p">})</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="n">serializable_losses</span> <span class="o">=</span> <span class="n">uf</span><span class="o">.</span><span class="n">convert_to_serializable</span><span class="p">(</span><span class="n">training_losses</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">checkpoint_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">serializable_losses</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: JSON serialization error with training losses: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Save top 5 models based on training loss</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">model_info</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">top_models</span><span class="p">)):</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">experiment_path</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;best_model_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">_train_loss_</span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">.pth&#39;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_info</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">],</span> <span class="n">model_path</span><span class="p">)</span>
        
        <span class="c1"># Save corresponding configuration</span>
        <span class="n">config_path</span> <span class="o">=</span> <span class="n">experiment_path</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;best_model_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">_config.json&#39;</span>
        <span class="n">config_info</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;model_config&#39;</span><span class="p">:</span> <span class="n">model_info</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">],</span>
            <span class="s1">&#39;loss_config&#39;</span><span class="p">:</span> <span class="n">model_info</span><span class="p">[</span><span class="s1">&#39;loss_config&#39;</span><span class="p">],</span>
            <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span>
            <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">model_info</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
        <span class="p">}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">uf</span><span class="o">.</span><span class="n">convert_to_serializable</span><span class="p">(</span><span class="n">config_info</span><span class="p">),</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    
    <span class="c1"># Convert top models to serializable format with rounded values</span>
    <span class="n">top_models_json</span> <span class="o">=</span> <span class="p">[{</span>
        <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;config&quot;</span><span class="p">],</span>
        <span class="s2">&quot;loss_config&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;loss_config&quot;</span><span class="p">],</span>
        <span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">4</span><span class="p">),</span>
        <span class="s2">&quot;val_loss&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="mi">4</span><span class="p">)</span>
    <span class="p">}</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">top_models</span><span class="p">]</span>
    <span class="n">top_models_json</span> <span class="o">=</span> <span class="n">uf</span><span class="o">.</span><span class="n">convert_to_serializable</span><span class="p">(</span><span class="n">top_models_json</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">experiment_path</span> <span class="o">/</span> <span class="s2">&quot;top_models.json&quot;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">top_models_json</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: JSON serialization error with top model configurations: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;experiment_path&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">experiment_path</span><span class="p">),</span> <span class="s2">&quot;top_models&quot;</span><span class="p">:</span> <span class="n">top_models_json</span><span class="p">}</span></div>



<span class="c1">#TODO Use better names for variable here</span>
<div class="viewcode-block" id="CustomLoss">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.CustomLoss">[docs]</a>
<span class="k">class</span> <span class="nc">CustomLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Custom loss function for time series forecasting that combines multiple objectives:</span>
<span class="sd">    1. MSE for basic prediction accuracy</span>
<span class="sd">    2. Trend preservation loss to maintain price movement direction</span>
<span class="sd">    3. Volatility matching loss to maintain price variation patterns</span>
<span class="sd">    4. Momentum preservation loss to prevent asymptote convergence</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    alpha : float, default=0.4</span>
<span class="sd">        Weight for trend preservation loss</span>
<span class="sd">    beta : float, default=0.3</span>
<span class="sd">        Weight for volatility matching loss</span>
<span class="sd">    gamma : float, default=0.3</span>
<span class="sd">        Weight for momentum preservation loss</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        
<div class="viewcode-block" id="CustomLoss.forward">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.CustomLoss.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># Basic MSE loss</span>
        <span class="n">mse_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        
        <span class="c1"># Trend preservation loss</span>
        <span class="n">pred_diff</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">target_diff</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">targets</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">trend_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">pred_diff</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">target_diff</span><span class="p">)))</span>
        
        <span class="c1"># Volatility matching loss</span>
        <span class="n">pred_vol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        <span class="n">target_vol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
        <span class="n">vol_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pred_vol</span> <span class="o">-</span> <span class="n">target_vol</span><span class="p">)</span>
        
        <span class="c1"># Momentum preservation loss (prevents asymptote convergence)</span>
        <span class="n">pred_momentum</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">predictions</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">target_momentum</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">targets</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">targets</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">momentum_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pred_momentum</span> <span class="o">-</span> <span class="n">target_momentum</span><span class="p">))</span>
        
        <span class="c1"># Combine losses</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span> <span class="o">*</span> <span class="n">mse_loss</span> <span class="o">+</span> \
                    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">trend_loss</span> <span class="o">+</span> \
                    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="n">vol_loss</span> <span class="o">+</span> \
                    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">momentum_loss</span>
        
        <span class="k">return</span> <span class="n">total_loss</span></div>
</div>


<div class="viewcode-block" id="AsymptotePreventionLoss">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AsymptotePreventionLoss">[docs]</a>
<span class="k">class</span> <span class="nc">AsymptotePreventionLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loss function specifically designed to prevent asymptote convergence by:</span>
<span class="sd">    1. Penalizing predictions that deviate too far from the historical range</span>
<span class="sd">    2. Encouraging price movement continuation</span>
<span class="sd">    3. Maintaining realistic price changes</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    historical_range : tuple</span>
<span class="sd">        (min_price, max_price) from historical data</span>
<span class="sd">    max_daily_change : float</span>
<span class="sd">        Maximum allowed daily price change as a percentage</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">historical_range</span><span class="p">,</span> <span class="n">max_daily_change</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_price</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_price</span> <span class="o">=</span> <span class="n">historical_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_daily_change</span> <span class="o">=</span> <span class="n">max_daily_change</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        
<div class="viewcode-block" id="AsymptotePreventionLoss.forward">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AsymptotePreventionLoss.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># Basic MSE loss</span>
        <span class="n">mse_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        
        <span class="c1"># Range violation penalty</span>
        <span class="n">range_violation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">predictions</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_price</span><span class="p">)</span> <span class="o">+</span> 
                          <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_price</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">))</span>
        
        <span class="c1"># Daily change violation penalty</span>
        <span class="n">daily_changes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">predictions</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">change_violation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">daily_changes</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_daily_change</span><span class="p">))</span>
        
        <span class="c1"># Combine losses</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">mse_loss</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">range_violation</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">change_violation</span>
        
        <span class="k">return</span> <span class="n">total_loss</span></div>
</div>


<div class="viewcode-block" id="AdaptiveForecastLoss">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AdaptiveForecastLoss">[docs]</a>
<span class="k">class</span> <span class="nc">AdaptiveForecastLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    DEPRECATED severly broken</span>
<span class="sd">    Advanced loss function that incorporates multi-step forecasting and learnable parameters</span>
<span class="sd">    for dynamic adaptation to market conditions.</span>
<span class="sd">    </span>
<span class="sd">    This loss function:</span>
<span class="sd">    1. Performs multi-step forecasting within the loss calculation</span>
<span class="sd">    2. Uses learnable parameters to adapt penalties</span>
<span class="sd">    3. Implements dynamic scaling based on forecast horizon</span>
<span class="sd">    4. Combines multiple objectives with adaptive weights</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    historical_range : tuple</span>
<span class="sd">        (min_price, max_price) from historical data</span>
<span class="sd">    forecast_steps : int, default=5</span>
<span class="sd">        Number of future steps to consider in forecasting component</span>
<span class="sd">    init_max_change : float, default=0.1</span>
<span class="sd">        Initial value for maximum daily change parameter</span>
<span class="sd">    init_range_weight : float, default=0.5</span>
<span class="sd">        Initial weight for range violation penalty</span>
<span class="sd">    init_change_weight : float, default=0.3</span>
<span class="sd">        Initial weight for change violation penalty</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">historical_range</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">init_max_change</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">init_range_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">init_change_weight</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Create tensors on CPU initially</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;min_price&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">historical_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;max_price&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">historical_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;price_scale&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">historical_range</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">historical_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> 
                                                                  <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">forecast_steps</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># Limit forecast steps</span>
        
        <span class="c1"># Initialize learnable parameters with more stable values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_change</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">init_max_change</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">range_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">init_range_weight</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">change_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">init_change_weight</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
        
        <span class="c1"># Initialize horizon scaling with more conservative values</span>
        <span class="n">initial_scales</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">horizon_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">initial_scales</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
        
        <span class="c1"># Base loss functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
        
        <span class="c1"># Constants for numerical stability</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-6</span>
    
<div class="viewcode-block" id="AdaptiveForecastLoss.to">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AdaptiveForecastLoss.to">[docs]</a>
    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Override to method to handle device placement for all tensors&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># Move all tensors to the specified device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">price_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">price_scale</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_change</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_change</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">range_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">range_weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">change_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">change_weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">horizon_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">horizon_scale</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

        
<div class="viewcode-block" id="AdaptiveForecastLoss.forecast_loss">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AdaptiveForecastLoss.forecast_loss">[docs]</a>
    <span class="k">def</span> <span class="nf">forecast_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate loss across multiple forecast steps with increasing uncertainty&quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span>
        <span class="n">total_forecast_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Ensure all tensors are on the same device</span>
        <span class="n">min_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">max_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Early return if batch is too small</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        
        <span class="c1"># Calculate immediate prediction loss with full weight</span>
        <span class="n">immediate_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">min_price</span><span class="p">,</span> <span class="n">max_price</span><span class="p">),</span> 
                                <span class="n">targets</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">min_price</span><span class="p">,</span> <span class="n">max_price</span><span class="p">))</span>
        <span class="n">total_forecast_loss</span> <span class="o">+=</span> <span class="n">immediate_loss</span>
        
        <span class="c1"># Calculate multi-step forecast loss with increasing uncertainty</span>
        <span class="n">valid_steps</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">valid_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">valid_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="c1"># Get prediction and target for this step</span>
                <span class="n">step_pred</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[:</span><span class="o">-</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">min_price</span><span class="p">,</span> <span class="n">max_price</span><span class="p">)</span>
                <span class="n">step_target</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">step</span><span class="p">:]</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">min_price</span><span class="p">,</span> <span class="n">max_price</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">step_pred</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Calculate base step loss</span>
                    <span class="n">step_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">step_pred</span><span class="p">,</span> <span class="n">step_target</span><span class="p">)</span>
                    
                    <span class="c1"># Apply decreasing weight for longer horizons</span>
                    <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">horizon_scale</span><span class="p">[</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                    <span class="n">total_forecast_loss</span> <span class="o">+=</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">step_loss</span>
            
            <span class="c1"># Normalize with a stable denominator</span>
            <span class="n">total_forecast_loss</span> <span class="o">=</span> <span class="n">total_forecast_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">total_forecast_loss</span></div>

    
<div class="viewcode-block" id="AdaptiveForecastLoss.adaptive_range_penalty">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AdaptiveForecastLoss.adaptive_range_penalty">[docs]</a>
    <span class="k">def</span> <span class="nf">adaptive_range_penalty</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate adaptive range violation penalty with increasing bounds&quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span>
        
        <span class="c1"># Ensure all tensors are on the same device</span>
        <span class="n">min_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">max_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">price_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">price_scale</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Calculate normalized predictions with clamping</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">min_price</span> <span class="o">-</span> <span class="n">price_scale</span><span class="p">,</span> <span class="n">max_price</span> <span class="o">+</span> <span class="n">price_scale</span><span class="p">)</span>
        <span class="n">norm_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">min_price</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">price_scale</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        
        <span class="c1"># Expanding boundaries over time with stability</span>
        <span class="n">sequence_pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">sequence_pos</span> <span class="o">=</span> <span class="n">sequence_pos</span> <span class="o">/</span> <span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">expansion_factor</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="n">sequence_pos</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Soft boundaries with expanding margins</span>
        <span class="n">margin</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">expansion_factor</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
        <span class="n">upper_violation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">norm_predictions</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">margin</span><span class="p">))</span>
        <span class="n">lower_violation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="o">-</span><span class="n">norm_predictions</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">margin</span><span class="p">))</span>
        
        <span class="c1"># Combine violations with reduced penalty for later timesteps</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">upper_violation</span> <span class="o">+</span> <span class="n">lower_violation</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">expansion_factor</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">penalty</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>  <span class="c1"># Prevent extreme penalties</span></div>

    
<div class="viewcode-block" id="AdaptiveForecastLoss.adaptive_change_penalty">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AdaptiveForecastLoss.adaptive_change_penalty">[docs]</a>
    <span class="k">def</span> <span class="nf">adaptive_change_penalty</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate adaptive change penalty with increasing allowance&quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span>
        
        <span class="c1"># Ensure all tensors are on the same device</span>
        <span class="n">min_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">max_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">price_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">price_scale</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">max_change</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_change</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Normalize predictions with clamping</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">min_price</span><span class="p">,</span> <span class="n">max_price</span><span class="p">)</span>
        <span class="n">norm_predictions</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">/</span> <span class="p">(</span><span class="n">price_scale</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        
        <span class="c1"># Calculate relative changes</span>
        <span class="n">diffs</span> <span class="o">=</span> <span class="n">norm_predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">norm_predictions</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Allow larger changes over time with stability</span>
        <span class="n">sequence_pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">diffs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">sequence_pos</span> <span class="o">=</span> <span class="n">sequence_pos</span> <span class="o">/</span> <span class="p">(</span><span class="n">diffs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">max_change_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">max_change</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.2</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">sequence_pos</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Calculate penalty with increasing tolerance</span>
        <span class="n">changes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">diffs</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">changes</span> <span class="o">-</span> <span class="n">max_change_val</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">sequence_pos</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">penalty</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>  <span class="c1"># Prevent extreme penalties</span></div>

    
<div class="viewcode-block" id="AdaptiveForecastLoss.momentum_continuity">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AdaptiveForecastLoss.momentum_continuity">[docs]</a>
    <span class="k">def</span> <span class="nf">momentum_continuity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate momentum with increasing flexibility&quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="c1"># Ensure all tensors are on the same device</span>
        <span class="n">min_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">max_price</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_price</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">price_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">price_scale</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Normalize predictions with clamping</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">min_price</span><span class="p">,</span> <span class="n">max_price</span><span class="p">)</span>
        <span class="n">norm_predictions</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">/</span> <span class="p">(</span><span class="n">price_scale</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        
        <span class="c1"># Calculate second-order differences with increasing tolerance</span>
        <span class="n">momentum</span> <span class="o">=</span> <span class="n">norm_predictions</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">norm_predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">norm_predictions</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        
        <span class="c1"># Allow more momentum variation over time with stability</span>
        <span class="n">sequence_pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">momentum</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">sequence_pos</span> <span class="o">=</span> <span class="n">sequence_pos</span> <span class="o">/</span> <span class="p">(</span><span class="n">momentum</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">tolerance</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">sequence_pos</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>
        
        <span class="c1"># Reduced penalty for later timesteps</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">momentum</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">tolerance</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">penalty</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>  <span class="c1"># Prevent extreme penalties</span></div>

    
<div class="viewcode-block" id="AdaptiveForecastLoss.forward">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.AdaptiveForecastLoss.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate total loss with natural uncertainty growth&quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="c1"># Ensure all parameters are on the correct device</span>
        <span class="n">range_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">range_weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">change_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">change_weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Base prediction loss with clamping</span>
        <span class="n">forecast_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        
        <span class="c1"># Calculate penalties with learnable weights and stability</span>
        <span class="n">range_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">range_weight</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">change_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">change_weight</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        
        <span class="c1"># Calculate penalties</span>
        <span class="n">range_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adaptive_range_penalty</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        <span class="n">change_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adaptive_change_penalty</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        <span class="n">momentum_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum_continuity</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        
        <span class="c1"># Combine components with stability</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">forecast_loss</span> <span class="o">+</span>  <span class="c1"># Main prediction loss</span>
            <span class="n">range_w</span> <span class="o">*</span> <span class="n">range_penalty</span> <span class="o">+</span>  <span class="c1"># Flexible range constraints</span>
            <span class="n">change_w</span> <span class="o">*</span> <span class="n">change_penalty</span> <span class="o">+</span>  <span class="c1"># Adaptive change allowance</span>
            <span class="mf">0.1</span> <span class="o">*</span> <span class="n">momentum_penalty</span>  <span class="c1"># Light momentum guidance</span>
        <span class="p">)</span>
        
        <span class="c1"># Final stability check</span>
        <span class="k">return</span> <span class="n">total_loss</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1e6</span><span class="p">)</span>  <span class="c1"># Prevent infinite loss values</span></div>
</div>


<div class="viewcode-block" id="DirectionalLoss">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.DirectionalLoss">[docs]</a>
<span class="k">class</span> <span class="nc">DirectionalLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A simple loss function that combines MSE with cosine similarity to ensure</span>
<span class="sd">    predictions follow the correct directional trend.</span>
<span class="sd">    </span>
<span class="sd">    This loss function:</span>
<span class="sd">    1. Uses normalized MSE (bounded between 0 and 1) for point-wise accuracy</span>
<span class="sd">    2. Uses cosine similarity to ensure directional alignment</span>
<span class="sd">    3. Combines both metrics with a weighted sum</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    direction_weight : float, default=0.3</span>
<span class="sd">        Weight given to the directional (cosine) component of the loss.</span>
<span class="sd">        The MSE component will have weight (1 - direction_weight).</span>
<span class="sd">    mse_scale : float, default=10.0</span>
<span class="sd">        Scale factor for MSE normalization. Higher values make the sigmoid</span>
<span class="sd">        transition sharper around smaller MSE values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">direction_weight</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">mse_scale</span><span class="o">=</span><span class="mf">10.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">direction_weight</span> <span class="o">=</span> <span class="n">direction_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse_scale</span> <span class="o">=</span> <span class="n">mse_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cos</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineSimilarity</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
<div class="viewcode-block" id="DirectionalLoss.forward">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.DirectionalLoss.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># Ensure inputs are on the same device</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Calculate MSE component and normalize it to [0, 1]</span>
        <span class="n">mse_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="c1"># Use sigmoid to bound MSE between 0 and 1</span>
        <span class="c1"># Scale MSE to make sigmoid more sensitive to relevant error ranges</span>
        <span class="n">normalized_mse</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mse_scale</span> <span class="o">*</span> <span class="n">mse_loss</span><span class="p">)</span>
        
        <span class="c1"># Calculate directional component using cosine similarity</span>
        <span class="c1"># Reshape predictions and targets to 1D for cosine similarity</span>
        <span class="n">pred_flat</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">target_flat</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Cosine similarity returns 1 for identical directions, -1 for opposite</span>
        <span class="c1"># Convert to a loss (0 for identical, 1 for opposite)</span>
        <span class="n">direction_loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pred_flat</span><span class="p">,</span> <span class="n">target_flat</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
        
        <span class="c1"># Combine losses with weights (both components now bounded [0, 1])</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">normalized_mse</span> <span class="o">+</span> \
                    <span class="bp">self</span><span class="o">.</span><span class="n">direction_weight</span> <span class="o">*</span> <span class="n">direction_loss</span>
        
        <span class="k">return</span> <span class="n">total_loss</span></div>
</div>


<div class="viewcode-block" id="ForecastBasedLoss">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ForecastBasedLoss">[docs]</a>
<span class="k">class</span> <span class="nc">ForecastBasedLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enhanced loss function that combines:</span>
<span class="sd">    1. Directional accuracy using cosine similarity</span>
<span class="sd">    2. Bounded MSE for point accuracy</span>
<span class="sd">    3. Volatility matching for realistic price movements</span>
<span class="sd">    4. Uncertainty-weighted multi-step forecasting</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : TransformerModel</span>
<span class="sd">        The model being trained, used to generate forecasts</span>
<span class="sd">    forecast_steps : int, default=5</span>
<span class="sd">        Number of steps to forecast for loss calculation</span>
<span class="sd">    forecast_weight : float, default=0.4</span>
<span class="sd">        Weight given to forecast-based loss vs immediate prediction loss</span>
<span class="sd">    temperature : float, default=0.1</span>
<span class="sd">        Temperature for forecast uncertainty</span>
<span class="sd">    num_samples : int, default=10</span>
<span class="sd">        Number of Monte Carlo samples for each forecast</span>
<span class="sd">    mse_scale : float, default=10.0</span>
<span class="sd">        Scale factor for MSE normalization in sigmoid</span>
<span class="sd">    direction_weight : float, default=0.4</span>
<span class="sd">        Weight for directional component in forecast evaluation</span>
<span class="sd">    volatility_weight : float, default=0.2</span>
<span class="sd">        Weight for volatility matching component</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">forecast_weight</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
                 <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">mse_scale</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">direction_weight</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">volatility_weight</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forecast_steps</span> <span class="o">=</span> <span class="n">forecast_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forecast_weight</span> <span class="o">=</span> <span class="n">forecast_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse_scale</span> <span class="o">=</span> <span class="n">mse_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">direction_weight</span> <span class="o">=</span> <span class="n">direction_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">volatility_weight</span> <span class="o">=</span> <span class="n">volatility_weight</span>
        
        <span class="c1"># Loss functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cos</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineSimilarity</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
<div class="viewcode-block" id="ForecastBasedLoss.calculate_step_losses">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ForecastBasedLoss.calculate_step_losses">[docs]</a>
    <span class="k">def</span> <span class="nf">calculate_step_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate all loss components for a single prediction step.</span>
<span class="sd">        All components are bounded between 0 and 1 using sigmoid for equal weighting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span>
        
        <span class="c1"># Bounded MSE loss</span>
        <span class="n">mse_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">normalized_mse</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mse_scale</span> <span class="o">*</span> <span class="n">mse_loss</span><span class="p">)</span>
        
        <span class="c1"># Directional loss using cosine similarity</span>
        <span class="n">pred_flat</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">target_flat</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Cosine similarity is already bounded [-1, 1], convert to [0, 1]</span>
        <span class="n">direction_loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pred_flat</span><span class="p">,</span> <span class="n">target_flat</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
        
        <span class="c1"># Volatility matching loss - normalize using sigmoid</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">pred_volatility</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
            <span class="n">target_volatility</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
            <span class="c1"># Scale relative volatility difference before sigmoid</span>
            <span class="n">rel_vol_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pred_volatility</span> <span class="o">-</span> <span class="n">target_volatility</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">target_volatility</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
            <span class="n">volatility_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mse_scale</span> <span class="o">*</span> <span class="n">rel_vol_diff</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">volatility_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            
        <span class="c1"># Momentum matching loss (new component)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">pred_momentum</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">predictions</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">target_momentum</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">targets</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">targets</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">momentum_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pred_momentum</span> <span class="o">-</span> <span class="n">target_momentum</span><span class="p">))</span>
            <span class="c1"># Normalize momentum difference</span>
            <span class="n">momentum_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mse_scale</span> <span class="o">*</span> <span class="n">momentum_diff</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">momentum_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;mse&#39;</span><span class="p">:</span> <span class="n">normalized_mse</span><span class="p">,</span>
            <span class="s1">&#39;direction&#39;</span><span class="p">:</span> <span class="n">direction_loss</span><span class="p">,</span>
            <span class="s1">&#39;volatility&#39;</span><span class="p">:</span> <span class="n">volatility_loss</span><span class="p">,</span>
            <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="n">momentum_loss</span>
        <span class="p">}</span></div>

        
<div class="viewcode-block" id="ForecastBasedLoss.generate_forecast_sequence">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ForecastBasedLoss.generate_forecast_sequence">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_forecast_sequence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_sequences</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate forecasts for each sequence in the batch.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_sequences : torch.Tensor</span>
<span class="sd">            Batch of input sequences [batch_size, seq_length, features]</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            (forecasts, forecast_stds) where:</span>
<span class="sd">            - forecasts: tensor of shape [batch_size, forecast_steps]</span>
<span class="sd">            - forecast_stds: tensor of shape [batch_size, forecast_steps]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">input_sequences</span><span class="o">.</span><span class="n">device</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Initialize storage for forecasts and their uncertainties</span>
        <span class="n">forecasts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_steps</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">forecast_stds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_steps</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Generate forecasts for each sequence</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">sequence</span> <span class="o">=</span> <span class="n">input_sequences</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Keep batch dimension</span>
            
            <span class="c1"># Generate forecast using model&#39;s method</span>
            <span class="n">forecast_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate_forecast</span><span class="p">(</span>
                <span class="n">initial_sequence</span><span class="o">=</span><span class="n">sequence</span><span class="p">,</span>
                <span class="n">num_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">forecast_steps</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span>
            <span class="p">)</span>
            
            <span class="c1"># Convert numpy arrays to tensors and store</span>
            <span class="n">forecasts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">forecast_results</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">forecast_stds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">forecast_results</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">forecasts</span><span class="p">,</span> <span class="n">forecast_stds</span></div>

    
<div class="viewcode-block" id="ForecastBasedLoss.forward">
<a class="viewcode-back" href="../api_reference.html#time_series_transfomer.ForecastBasedLoss.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate combined loss using immediate predictions and generated forecasts.</span>
<span class="sd">        All components are sigmoid-bounded and properly weighted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Calculate immediate prediction losses</span>
        <span class="n">immediate_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_step_losses</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        
        <span class="c1"># Combine immediate losses with equal weighting in [0, 1] range</span>
        <span class="n">immediate_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction_weight</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">volatility_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">immediate_losses</span><span class="p">[</span><span class="s1">&#39;mse&#39;</span><span class="p">]</span> <span class="o">+</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">direction_weight</span> <span class="o">*</span> <span class="n">immediate_losses</span><span class="p">[</span><span class="s1">&#39;direction&#39;</span><span class="p">]</span> <span class="o">+</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">volatility_weight</span> <span class="o">*</span> <span class="p">(</span>
                <span class="mf">0.7</span> <span class="o">*</span> <span class="n">immediate_losses</span><span class="p">[</span><span class="s1">&#39;volatility&#39;</span><span class="p">]</span> <span class="o">+</span> 
                <span class="mf">0.3</span> <span class="o">*</span> <span class="n">immediate_losses</span><span class="p">[</span><span class="s1">&#39;momentum&#39;</span><span class="p">]</span>  <span class="c1"># Add momentum component</span>
            <span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Get sequences from the model&#39;s last input</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;last_input_sequence&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">immediate_loss</span>
        
        <span class="n">input_sequences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_input_sequence</span>
        
        <span class="c1"># Generate forecasts for each sequence</span>
        <span class="n">forecasts</span><span class="p">,</span> <span class="n">forecast_stds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_forecast_sequence</span><span class="p">(</span><span class="n">input_sequences</span><span class="p">)</span>
        
        <span class="c1"># Calculate forecast-based loss components</span>
        <span class="n">forecast_losses</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># For each step we can evaluate (limited by available targets)</span>
        <span class="n">valid_steps</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">valid_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">valid_steps</span><span class="p">):</span>
                <span class="c1"># Get the relevant predictions and targets for this step</span>
                <span class="n">step_forecasts</span> <span class="o">=</span> <span class="n">forecasts</span><span class="p">[:</span><span class="o">-</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="p">]</span>
                <span class="n">step_targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
                <span class="n">step_stds</span> <span class="o">=</span> <span class="n">forecast_stds</span><span class="p">[:</span><span class="o">-</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="p">]</span>
                
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">step_forecasts</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Calculate all loss components for this step</span>
                    <span class="n">step_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_step_losses</span><span class="p">(</span>
                        <span class="n">step_forecasts</span><span class="p">,</span> 
                        <span class="n">step_targets</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                    <span class="p">)</span>
                    
                    <span class="c1"># Combine step losses with equal weighting</span>
                    <span class="n">step_loss</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction_weight</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">volatility_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">step_losses</span><span class="p">[</span><span class="s1">&#39;mse&#39;</span><span class="p">]</span> <span class="o">+</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">direction_weight</span> <span class="o">*</span> <span class="n">step_losses</span><span class="p">[</span><span class="s1">&#39;direction&#39;</span><span class="p">]</span> <span class="o">+</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">volatility_weight</span> <span class="o">*</span> <span class="p">(</span>
                            <span class="mf">0.7</span> <span class="o">*</span> <span class="n">step_losses</span><span class="p">[</span><span class="s1">&#39;volatility&#39;</span><span class="p">]</span> <span class="o">+</span> 
                            <span class="mf">0.3</span> <span class="o">*</span> <span class="n">step_losses</span><span class="p">[</span><span class="s1">&#39;momentum&#39;</span><span class="p">]</span>  <span class="c1"># Add momentum component</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    
                    <span class="c1"># Weight by uncertainty (also sigmoid bounded)</span>
                    <span class="n">uncertainty_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="o">-</span><span class="n">step_stds</span><span class="p">)</span>  <span class="c1"># Higher std = lower weight</span>
                    <span class="n">weighted_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">step_loss</span> <span class="o">*</span> <span class="n">uncertainty_weights</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                    <span class="n">forecast_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weighted_loss</span><span class="p">)</span>
        
        <span class="c1"># If we have forecast losses, combine them with immediate loss</span>
        <span class="k">if</span> <span class="n">forecast_losses</span><span class="p">:</span>
            <span class="n">forecast_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">forecast_losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="c1"># Both components are already bounded [0, 1], so their weighted sum will be too</span>
            <span class="n">total_loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">immediate_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_weight</span> <span class="o">*</span> <span class="n">forecast_loss</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">total_loss</span> <span class="o">=</span> <span class="n">immediate_loss</span>
        
        <span class="k">return</span> <span class="n">total_loss</span></div>
</div>

</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">CoffeeGPT 1.5.4 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">time_series_transfomer</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; Copyright 2025, John Hohman.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    </div>
  </body>
</html>